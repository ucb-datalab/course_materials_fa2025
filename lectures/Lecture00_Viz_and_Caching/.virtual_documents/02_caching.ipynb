!rm galaxy1000.csv
!rm test.csv
!rm -r joblib_cache











import time
import os
import io

import pandas as pd
import requests  # requests is the standard URL

external_file_location = "https://raw.githubusercontent.com/AstroHackWeek/AstroHackWeek2014/master/day4/galaxy1000.csv"
local_filename = os.path.basename(external_file_location)


# ATTEMPT 1: download the CSV and load it into a DataFrame
r = requests.get(external_file_location)
df = pd.read_csv(io.StringIO(r.text))
df





def get_galaxy_dataframe():
    """
    get the galaxy CSV file from SDSS if we dont have it already
    and parse it into a pandas DataFrame. Save the file
    for future use.
    
    Returns: dataframe
    """
    if not os.path.exists(local_filename):
        start = time.time()
        r = requests.get(external_file_location)

        # note: below is for smallish files. To download and save larger files
        # see https://stackoverflow.com/a/14114741
        with open(local_filename, 'w') as handle:
            handle.write(r.text)

        print(f"Wrote the file {local_filename} to disk")
        # from the Python object `r` instead of from disk to avoid disk IO
        df = pd.read_csv(io.StringIO(r.text))
        print(f"  Total time: {time.time() - start:0.3} sec")
    else:
        start = time.time()
        print(f"Reading the file {local_filename} from disk")
        df = pd.read_csv(local_filename)
        print(f"  Total time: {time.time() - start:0.3} sec")
    return df


#!rm galaxy1000.csv
get_galaxy_dataframe()





def get_and_parse_cached_remote_csvfile(url, local_filename=None, verbose=True):
    """
    get a CSV file at `url` if we dont have it already
    and parse it into a pandas DataFrame. Save the file
    for future use. Guess the output filename if not given.
    
    Returns: dataframe
    """
    
    # here we might error check to see if the URL is valid, points to a CSV file
    # etc.
    if local_filename is None:
        local_filename = os.path.basename(url)
        
    if not os.path.exists(local_filename):
        start = time.time()
        r = requests.get(url)

        # note: below is for smallish files. To download and save larger files
        # see https://stackoverflow.com/a/14114741
        with open(local_filename, 'w') as handle:
            handle.write(r.text)
        if verbose:
            print(f"Wrote the file {local_filename} to disk", flush=True)
        # from the Python object `r` instead of from disk to avoid disk IO
        df = pd.read_csv(io.StringIO(r.text))
        if verbose:
            print(f"  Total time: {time.time() - start:0.3} sec")
    else:
        start = time.time()
        if verbose:
            print(f"Reading the file {local_filename} from disk")
        df = pd.read_csv(local_filename)
        if verbose:
            print(f"  Total time: {time.time() - start:0.3} sec")
    return df


df = get_and_parse_cached_remote_csvfile(external_file_location)


df = get_and_parse_cached_remote_csvfile(external_file_location, 
                                         local_filename="test.csv", verbose=False)





import astropy.units as u
from astropy.coordinates import SkyCoord
from astroquery.gaia import Gaia





query = """ -- Get some nearby sources
        SELECT top 1000 
            ra,dec,source_id,parallax,pm
        FROM gaiadr3.gaia_source 
        WHERE parallax_over_error > 15.0
            AND parallax > 200.0
        ORDER BY parallax DESC"""


def get_gaia_query(q):
    start = time.time()
    job = Gaia.launch_job(q)
    print(f"Total time: {time.time()-start:0.2f} sec")
    return job.get_results()

result_table = get_gaia_query(query)
print(result_table)








from joblib import Memory
cachedir = './joblib_cache'
memory = Memory(cachedir, verbose=0, bytes_limit=1e7)


@memory.cache
def get_gaia_query(q):
    start = time.time()
    job = Gaia.launch_job(q)
    print(f"Total time: {time.time()-start:0.2f} sec")
    return job.get_results()





result_table = get_gaia_query(query)


%time result_table = get_gaia_query(query)





def get_weather_alerts(area="CA"):
    r = requests.get(f"https://api.weather.gov/alerts/active?area={area}")
    zone = r.json()["features"][0]["properties"]["areaDesc"]
    return f'{zone}: {r.json()["features"][0]["properties"]["headline"]}'


print(get_weather_alerts())



