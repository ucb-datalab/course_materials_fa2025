{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Savio HPC for Training Neural Nets\n",
    "\n",
    "Saaht Mogan, AY128 UC Berkeley (SP 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Use a computing cluster?\n",
    "**Handling Large Datasets:**\n",
    "\n",
    "Astrophysics involves massive datasets (e.g., telescope observations, \n",
    "cosmological simulations). HPCs accelerate processing tasks that would take \n",
    "days on a personal computer. We'll see an example of this later.\n",
    "\n",
    "**Parallel Computing:**\n",
    "\n",
    "HPC clusters like Savio allow parallel execution of tasks across multiple \n",
    "CPUs/GPUs, critical for simulations or parameter sweeps.\n",
    "\n",
    "**Examples:**\n",
    "* Analyzing galaxy survey data (e.g., DESI, LSST).\n",
    "* Running N-body simulations for dark matter studies.\n",
    "* **Training machine learning models on astronomical images.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Savio Cluster Basics\n",
    "**Cluster Architecture**\n",
    "* Login Nodes: Lightweight tasks (editing code, job submission).\n",
    "* Compute Nodes: Heavy computations (request via SLURM).\n",
    "* Partitions: Groups of nodes with specific resources (e.g., `savio2_1080ti` \n",
    "for GPU jobs).\n",
    "\n",
    "**Storage Options**\n",
    "* Home Directory: Small, for critical files.\n",
    "* Scratch: High-speed storage for temporary job data.\n",
    "* Condos: Purchased storage for large projects.\n",
    "\n",
    "**Job Scheduling (SLURM)**\n",
    "* SLURM manages resource allocation.\n",
    "* Submit jobs via `sbatch job.sh`.\n",
    "* Monitor jobs with `squeue -u $USER`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using Savio: Step-by-Step\n",
    "**Important Links**\n",
    "* https://mybrc.brc.berkeley.edu/\n",
    "    * Portal for managing your access to different computing projects\n",
    "* https://docs-research-it.berkeley.edu/services/high-performance-computing/\n",
    "    * Documentation for how to use the cluster\n",
    "* https://ood.brc.berkeley.edu/\n",
    "    * The On Demand portal: the simplest way to interface with the cluster\n",
    "\n",
    "**Accessing Savio and File Transfer**\n",
    "* Access, transfer files, edit files, and submit jobs from the On Demand portal\n",
    "\n",
    "**Making a Job Script**\n",
    "The required items for all job scripts is bolded. We will go over the main \n",
    "`SBATCH` options we use for our jobs.\n",
    "\n",
    "* **Account** (`--account=fc_dweisz`)\n",
    "    * We are using Prof. Weisz's faculty allocation (Don't use too many SUs)\n",
    "* **Node Partition** (`--partition=savio2_1080ti`)\n",
    "    * This is the \"cheapest\" node with GPUs, more than enough compute for us\n",
    "* GPU (`--gres=gpu:1`)\n",
    "* CPUs (`--cpus-per-task=2`)\n",
    "    * `savio2_1080ti` nodes need 2 CPU cores for each GPU requested\n",
    "* **Time limit**: 10-minute runtime (`--time=00:10:00`)\n",
    "    * The job will stop itself after this time limit is reached whether or not \n",
    "    the job is complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Example Time!\n",
    "For our example, we are going to be training a ResNet model \n",
    "(see lab document for details) to classify images from the CIFAR-10 dataset. \n",
    "This dataset aims to classify 32x32 images into 1 of 10 different classes: \n",
    "plane, car, bird, cat, deer, dog, frog, horse, ship, and truck. Similar to our\n",
    "problem but we are guessing continuous labels, not discrete classes. This \n",
    "changes our code slightly but the gist of the example remains the same. As \n",
    "outlined in the lab, our broad steps are the same:\n",
    "\n",
    "1. Load in our data in a memory-friendly way\n",
    "2. Initialize our model with an appropriate loss function, optimizer, and \n",
    "    (learning rate scheduler).\n",
    "3. Finally run a training-validation loop over how many ever epochs we want to \n",
    "    train for.\n",
    "\n",
    "\n",
    "![Examples from the CIFAR-10 dataset](cifar10_images.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train this model for 5 epochs 3 different ways:\n",
    "1. Personal Computer on the CPU\n",
    "    * Wayyyyy too slow for repeated iterating\n",
    "2. Personal Computer on the GPU\n",
    "    * Possible, but inconvienient\n",
    "3. On Savio\n",
    "    * Set it, and (hopefully) forget it"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
